{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINI Interview Agent\n",
    "\n",
    "A streamlined agent for conducting MINI (Mini International Neuropsychiatric Interview) assessments with intelligent response analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.3.26)\n",
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.98.0)\n",
      "Requirement already satisfied: tiktoken in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: langchain-openai in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.3.28)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (0.3.70)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (0.4.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (2.11.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.13.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain openai tiktoken langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API key loaded (ends with: ...cmKxGpLUIA)\n",
      "API key configured\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def get_key():\n",
    "    \"\"\"Get OpenAI API key from .env file, environment, or user input.\"\"\"\n",
    "    # Clear any cached API key\n",
    "    if 'OPENAI_API_KEY' in os.environ:\n",
    "        del os.environ['OPENAI_API_KEY']\n",
    "    \n",
    "    # Load environment variables from .env file (force reload)\n",
    "    load_dotenv(override=True)\n",
    "    \n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    if not api_key:\n",
    "        api_key = getpass.getpass('Enter your OpenAI API key: ')\n",
    "        os.environ['OPENAI_API_KEY'] = api_key\n",
    "    \n",
    "    # Verify key format\n",
    "    if api_key and not api_key.startswith('sk-'):\n",
    "        print(\"⚠️  Warning: API key doesn't start with 'sk-'\")\n",
    "    \n",
    "    print(f\"✅ API key loaded (ends with: ...{api_key[-10:] if api_key else 'None'})\")\n",
    "    return api_key\n",
    "\n",
    "# Set up API key\n",
    "get_key()\n",
    "print(\"API key configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core interview tools defined successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "@tool\n",
    "def ask_patient(question: str) -> str:\n",
    "    \"\"\"Ask the patient the current MINI question and get their response.\"\"\"\n",
    "    print(f\"Clinician: {question}\")\n",
    "    patient_response = input(\"Patient: \")\n",
    "    print(f\"Patient response: {patient_response}\")  # Print patient answer\n",
    "    return patient_response\n",
    "\n",
    "def analyze_response(response: str, question_context: str) -> str:\n",
    "    \"\"\"Use LLM to analyze and classify patient's response as 'yes', 'no', or 'unclear' based on clinical context.\"\"\"\n",
    "    \n",
    "    # Pre-filter common unclear responses to avoid LLM misclassification\n",
    "    unclear_patterns = [\n",
    "        \"i don't know\", \"i dont know\", \"idk\", \"not sure\", \"maybe\", \"i'm not sure\",\n",
    "        \"i am not sure\", \"uncertain\", \"hard to say\", \"depends\", \"sometimes\",\n",
    "        \"kind of\", \"sort of\", \"partially\", \"it varies\", \"i think so but\",\n",
    "        \"i'm confused\", \"i am confused\", \"what do you mean\", \"can you repeat\"\n",
    "    ]\n",
    "    \n",
    "    response_lower = response.lower().strip()\n",
    "    \n",
    "    # Check for explicit unclear responses first\n",
    "    for pattern in unclear_patterns:\n",
    "        if pattern in response_lower:\n",
    "            return 'unclear'\n",
    "    \n",
    "    # If not obviously unclear, use LLM analysis\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "    \n",
    "    analysis_prompt = PromptTemplate(\n",
    "        input_variables=[\"response\", \"question_context\"],\n",
    "        template=\"\"\"You are a skilled clinician analyzing a patient's response to a MINI interview question.\n",
    "\n",
    "Question context: {question_context}\n",
    "Patient response: \"{response}\"\n",
    "\n",
    "Analyze this response and classify it as exactly one of: 'yes', 'no', or 'unclear'\n",
    "\n",
    "CRITICAL GUIDELINES:\n",
    "- 'yes': Patient clearly and definitively indicates affirmative (agreement, presence of symptoms, positive response)\n",
    "- 'no': Patient clearly and definitively indicates negative (disagreement, absence of symptoms, negative response)  \n",
    "- 'unclear': ANY ambiguous, uncertain, contradictory, or hesitant response that needs clarification\n",
    "\n",
    "IMPORTANT: If there is ANY doubt about the patient's intent, classify as 'unclear'. Better to ask for clarification than to misclassify.\n",
    "\n",
    "Examples of UNCLEAR responses:\n",
    "- \"I don't know\", \"Maybe\", \"Sometimes\", \"It depends\", \"Not sure\", \"Kind of\", \"Sort of\"\n",
    "- Any response with uncertainty markers like \"I think\", \"I guess\", \"Probably\"\n",
    "- Contradictory statements or requests for clarification\n",
    "\n",
    "Respond with ONLY the classification word: yes, no, or unclear\"\"\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        result = analysis_prompt.format(response=response, question_context=question_context)\n",
    "        llm_response = llm.invoke(result)\n",
    "        \n",
    "        # Extract and clean the classification\n",
    "        classification = llm_response.content.strip().lower()\n",
    "        \n",
    "        # More strict classification logic\n",
    "        if classification == 'yes':\n",
    "            return 'yes'\n",
    "        elif classification == 'no':\n",
    "            return 'no'\n",
    "        else:\n",
    "            # Default to unclear if LLM gives anything other than clear yes/no\n",
    "            return 'unclear'\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in LLM analysis: {e}\")\n",
    "        return 'unclear'\n",
    "\n",
    "@tool\n",
    "def analyze_response_tool(response: str, question_context: str) -> str:\n",
    "    \"\"\"Tool version of analyze_response for agent use.\"\"\"\n",
    "    return analyze_response(response, question_context)\n",
    "\n",
    "def ask_clarification(original_question: str, unclear_response: str) -> str:\n",
    "    \"\"\"Ask the patient to clarify their unclear response with an LLM-generated follow-up question.\"\"\"\n",
    "    \n",
    "    # Use LLM to generate a contextually appropriate clarification question\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "    \n",
    "    clarification_prompt = PromptTemplate(\n",
    "        input_variables=[\"original_question\", \"unclear_response\"],\n",
    "        template=\"\"\"You are a skilled clinician conducting a MINI interview. The patient gave an unclear response that needs clarification.\n",
    "\n",
    "Original question: \"{original_question}\"\n",
    "Patient's unclear response: \"{unclear_response}\"\n",
    "\n",
    "Generate a professional, empathetic clarification question that:\n",
    "1. Acknowledges the patient's response respectfully\n",
    "2. Gently asks for a clearer yes/no answer\n",
    "3. May rephrase the original question if helpful\n",
    "4. Uses natural, conversational language\n",
    "5. Shows clinical empathy and understanding\n",
    "\n",
    "The goal is to help the patient provide a clear yes or no response while maintaining rapport.\n",
    "\n",
    "Clarification question:\"\"\"\n",
    "    )\n",
    "        # Generate the clarification question using LLM\n",
    "    result = clarification_prompt.format(\n",
    "        original_question=original_question, \n",
    "        unclear_response=unclear_response\n",
    "    )\n",
    "    llm_response = llm.invoke(result)\n",
    "    clarification_question = llm_response.content.strip()\n",
    "        \n",
    "    # Present the LLM-generated clarification question\n",
    "    print(f\"Clinician: {clarification_question}\")\n",
    "    patient_response = input(\"Patient: \")\n",
    "    print(f\"Patient response: {patient_response}\")\n",
    "    return patient_response\n",
    "\n",
    "@tool\n",
    "def ask_clarification_tool(original_question: str, unclear_response: str) -> str:\n",
    "    \"\"\"Tool version of ask_clarification for agent use.\"\"\"\n",
    "    return ask_clarification(original_question, unclear_response)\n",
    "\n",
    "@tool\n",
    "def explain(current_question: str) -> str:\n",
    "    \"\"\"Clarify or rephrase the current question to help the patient understand.\"\"\"\n",
    "    explanations = {\n",
    "        \"anxiety\": \"Anxiety means feeling worried, nervous, or uneasy about something.\",\n",
    "        \"panic\": \"Panic symptoms include rapid heartbeat, sweating, trembling, or feeling like you can't breathe.\",\n",
    "        \"agoraphobia\": \"This refers to fear of being in places where escape might be difficult or help unavailable.\",\n",
    "        \"avoidance\": \"Avoidance means staying away from situations that make you uncomfortable.\"\n",
    "    }\n",
    "    \n",
    "    explanation = f\"Let me clarify: {current_question}\\n\\n\"\n",
    "    for key, value in explanations.items():\n",
    "        if key in current_question.lower():\n",
    "            explanation += f\"Note: {value}\\n\"\n",
    "    \n",
    "    return explanation\n",
    "\n",
    "@tool\n",
    "def end_module() -> str:\n",
    "    \"\"\"Signal that the module has ended either due to logic or patient response.\"\"\"\n",
    "    return \"Module assessment complete. Thank you for your responses.\"\n",
    "\n",
    "@tool\n",
    "def get_next_question(current_question_id: str, patient_answer: str, question_context: str) -> str:\n",
    "    \"\"\"Determine the next question based on current question and patient's LLM-analyzed answer.\"\"\"\n",
    "    # Check if questions dictionary exists\n",
    "    try:\n",
    "        if current_question_id not in questions:\n",
    "            return \"END_MODULE\"\n",
    "        \n",
    "        branching = questions[current_question_id].get(\"next\", {})\n",
    "        classified_answer = analyze_response(patient_answer, question_context)  # Uses the regular function\n",
    "        \n",
    "        next_q = branching.get(classified_answer, \"END_MODULE\")\n",
    "        \n",
    "        if next_q == \"END_MODULE\":\n",
    "            return \"END_MODULE\"\n",
    "        elif next_q in questions:\n",
    "            return questions[next_q][\"prompt\"]\n",
    "        else:\n",
    "            return \"END_MODULE\"\n",
    "    except NameError:\n",
    "        # If questions is not defined yet, return a placeholder\n",
    "        print(\"Warning: questions dictionary not loaded yet\")\n",
    "        return \"QUESTIONS_NOT_LOADED\"\n",
    "\n",
    "# TODO: This is not working as expected. Need to fix it. For now we are going to use a simple yes/no criteria\n",
    "# to determine diagnosis, not an LLM tool.\n",
    "# @tool\n",
    "# def evaluate_diagnosis_from_log(conversation_log, criteria_rules, module_name):\n",
    "    \"\"\"\n",
    "    Evaluate diagnosis based on conversation log and diagnostic rules.\n",
    "\n",
    "    Parameters:\n",
    "        conversation_log (list of dicts): Each dict has question_id, classification, etc.\n",
    "        criteria_rules (dict): e.g., {'agoraphobia': {'current': \"E6 == 'YES'\"}}\n",
    "        module_name (str): e.g., \"agoraphobia\"\n",
    "\n",
    "    Returns:\n",
    "        str: \"yes\" or \"no\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Extract relevant patient answers for the target module\n",
    "    patient_responses = {}\n",
    "    for entry in conversation_log:\n",
    "        qid = entry.get(\"question_id\")\n",
    "        classification = entry.get(\"classification\")\n",
    "        if qid and classification:\n",
    "            patient_responses[qid] = classification.strip().upper()\n",
    "\n",
    "    # Step 2: Get the rule for the specified diagnosis\n",
    "    rule = criteria_rules.get(module_name.lower(), {}).get('current', None)\n",
    "    if not rule:\n",
    "        raise ValueError(f\"No criteria rule found for module '{module_name}'.\")\n",
    "\n",
    "    # Step 3: Prepare inputs for the LLM prompt\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"response\", \"criteria\"],\n",
    "        template=(\n",
    "            \"You are a psychiatric diagnostic evaluator.\\n\"\n",
    "            \"Based on the patient's responses:\\n\\n\"\n",
    "            \"{response}\\n\\n\"\n",
    "            \"And the diagnostic rule:\\n\"\n",
    "            \"{criteria}\\n\\n\"\n",
    "            \"Does the patient meet the criteria for this disorder?\\n\"\n",
    "            \"Answer only with 'Yes' or 'No'.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    formatted_response = \"\\n\".join(f\"{k}: {v}\" for k, v in patient_responses.items())\n",
    "    final_prompt = prompt.format(response=formatted_response, criteria=rule)\n",
    "\n",
    "    # Step 4: Send prompt to LLM and normalize output\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "    classification_response = llm([HumanMessage(content=final_prompt)])\n",
    "    classification = classification_response.content.strip().lower()\n",
    "\n",
    "    if \"yes\" in classification:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# List of tools for the agent (clean and focused)\n",
    "tools = [ask_patient, analyze_response_tool, ask_clarification_tool, explain, end_module, get_next_question]\n",
    "\n",
    "print(\"Core interview tools defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Load MINI Questions (Module E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 questions for Module E: Agoraphobia\n",
      "\n",
      "1. E1: Do you feel anxious or uneasy in places or situations where help might not be available or escape difficult if you had a panic-like or embarrassing symptom, such as being in a crowd or queue, in an open space or crossing a bridge, in an enclosed space, when alone away from home, when alone at home, or traveling in a bus, train, car, or using public transportation?\n",
      "\n",
      "2. E2: Do these situations almost always bring on fear or anxiety?\n",
      "\n",
      "Branching for E1:\n",
      "{'yes': 'E2', 'no': 'END_MODULE'}\n"
     ]
    }
   ],
   "source": [
    "# Load module data\n",
    "import json, pprint\n",
    "\n",
    "PATH = \"mini_modules/working/module_e.json\" \n",
    "with open(PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    module_data = json.load(f)\n",
    "\n",
    "mini_script = module_data[\"questions\"]     \n",
    "module_info = module_data[\"module\"] \n",
    "module_diagnostic_criteria = module_data[\"diagnosticCriteria\"]\n",
    "\n",
    "# Prepare questions dictionary for easy access\n",
    "questions = {q[\"id\"]: q for q in mini_script}\n",
    "\n",
    "print(f\"Loaded {len(mini_script)} questions for Module {module_info['id']}: {module_info['name']}\\n\")\n",
    "\n",
    "for i, q in enumerate(mini_script[:2], start=1):\n",
    "    print(f\"{i}. {q['id']}: {q['prompt']}\\n\")\n",
    "\n",
    "# Branching logic retrieval function\n",
    "def show_branches(qid: str):\n",
    "    if qid not in questions:\n",
    "        raise KeyError(f\"{qid!r} not found\")\n",
    "    next = questions[qid].get(\"next\", {})\n",
    "    print(f\"Branching for {qid}:\")\n",
    "    pprint.pp(next)\n",
    "\n",
    "# Example: inspect the first question’s branches\n",
    "show_branches(\"E1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\", \"question\"],\n",
    "    template=\"\"\"You are an AI agent with the role of a skilled clinician trained in professional physchological diagnosis and care conducting an interview based on the MINI questionnaire. Be concise, empathetic, and professional.\n",
    "\n",
    "Previous conversation:\n",
    "{history}\n",
    "\n",
    "Next question to ask:\n",
    "{question}\n",
    "\n",
    "Present this question in a natural, conversational way. Keep your response brief and focused, ask the question prompting a yes or no response from the patient.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Class to Manage Interview State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interview tools ready: ask_patient, analyze_response, ask_clarification, explain\n"
     ]
    }
   ],
   "source": [
    "# Interview State Management\n",
    "import datetime\n",
    "\n",
    "class InterviewState:\n",
    "    def __init__(self):\n",
    "        self.current_question_id = \"E1\"\n",
    "        self.conversation_log = []\n",
    "        self.is_complete = False\n",
    "        self.interview_start_time = None\n",
    "        self.is_diagnosis = None\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_question_id = \"E1\"\n",
    "        self.conversation_log = []\n",
    "        self.is_complete = False\n",
    "        self.interview_start_time = datetime.datetime.now()\n",
    "        self.is_diagnosis = None\n",
    "\n",
    "# Initialize global state\n",
    "interview_state = InterviewState()\n",
    "\n",
    "# Core tools for the interview agent (keeping the essential ones)\n",
    "print(\"Interview tools ready: ask_patient, analyze_response, ask_clarification, explain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Determine the Diagnosis Based on Interview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_diagnosis(conversation_log):\n",
    "    \"\"\"Determine the diagnosis based on the patient interview.\n",
    "    For now we are going to use a simple yes/no criteria to determine diagnosis.\n",
    "    Later we will use diagnostic criteria from the module to determine the diagnosis.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if all answers are 'yes', False if any answer is 'no' or 'unclear'\n",
    "    \"\"\"\n",
    "    \n",
    "    if not conversation_log:\n",
    "        return False\n",
    "        \n",
    "    for entry in conversation_log:\n",
    "        classification = entry.get('classification', '').lower()\n",
    "        if classification != 'yes':\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Export the Interview as a CSV Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "\n",
    "def export_results_to_csv():\n",
    "    \"\"\"Export the interview results to a CSV file.\"\"\"    \n",
    "    reports_dir = \"reports\"\n",
    "    if not os.path.exists(reports_dir):\n",
    "        os.makedirs(reports_dir)        \n",
    "    \n",
    "    # Use timestamp to name the file, guaranteed to be unique\n",
    "    if interview_state.interview_start_time:\n",
    "        timestamp = interview_state.interview_start_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    else:\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    filename = f\"mini_interview_{timestamp}.csv\"\n",
    "    filepath = os.path.join(reports_dir, filename)\n",
    "        \n",
    "    with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['Question ID', 'Question', 'Patient Response', 'Classification', 'Clarifications Needed']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        \n",
    "        for entry in interview_state.conversation_log:\n",
    "            writer.writerow({\n",
    "                'Question ID': entry['question_id'],\n",
    "                'Question': entry['question'],\n",
    "                'Patient Response': entry['patient_response'],\n",
    "                'Classification': entry['classification'],\n",
    "                'Clarifications Needed': entry.get('clarifications_needed', 0)\n",
    "            })\n",
    "    \n",
    "    print(f\"\\nResults exported to: {filepath}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified Agent-Based Interview Workflow\n",
    "def run_interview_with_agent():\n",
    "    \"\"\"Run the MINI interview with agent assistance for response analysis and clarification.\"\"\"\n",
    "    # Reset interview state\n",
    "    interview_state.reset()\n",
    "    \n",
    "    print(f\"Starting MINI Module {module_info['id']}: {module_info['name']}\")\n",
    "    print(\"Using AI Agent for intelligent response analysis and clarification\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Initialize LLM for agent decisions\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "    \n",
    "    while not interview_state.is_complete:\n",
    "        # Get current question\n",
    "        if interview_state.current_question_id == \"END_MODULE\":\n",
    "            break\n",
    "            \n",
    "        if interview_state.current_question_id not in questions:\n",
    "            print(\"No more questions available.\")\n",
    "            break\n",
    "            \n",
    "        current_question = questions[interview_state.current_question_id]\n",
    "        \n",
    "        # Display question\n",
    "        print(f\"\\n[Question {interview_state.current_question_id}]\")\n",
    "        print(f\"Clinician: {current_question['prompt']}\")\n",
    "        \n",
    "        # Get patient response\n",
    "        patient_response = input(\"Patient: \")\n",
    "        print(f\"Patient answered: {patient_response}\")\n",
    "        \n",
    "        # Use agent to analyze response\n",
    "        classification = analyze_response(patient_response, current_question['prompt'])\n",
    "        print(f\"LLM Analysis: {classification}\")\n",
    "        \n",
    "        # If unclear, use agent for clarification\n",
    "        max_clarifications = 2\n",
    "        clarification_count = 0\n",
    "        \n",
    "        while classification == 'unclear' and clarification_count < max_clarifications:\n",
    "            clarification_count += 1\n",
    "            print(f\"\\n[Clarification {clarification_count}/{max_clarifications}]\")\n",
    "            \n",
    "            # Get clarified response\n",
    "            clarified_response = ask_clarification(current_question['prompt'], patient_response)\n",
    "            print(f\"Clarified response: {clarified_response}\")\n",
    "            \n",
    "            # Re-analyze clarified response\n",
    "            classification = analyze_response(clarified_response, current_question['prompt'])\n",
    "            print(f\"LLM Analysis of clarification: {classification}\")\n",
    "            \n",
    "            # Update patient response to the clarified version\n",
    "            patient_response = clarified_response\n",
    "        \n",
    "        # If still unclear after max attempts, default to 'no'\n",
    "        if classification == 'unclear':\n",
    "            print(f\"Still unclear after {max_clarifications} attempts. Defaulting to 'no' to continue.\")\n",
    "            classification = 'no'\n",
    "        \n",
    "        # Log the interaction\n",
    "        interview_state.conversation_log.append({\n",
    "            \"question_id\": interview_state.current_question_id,\n",
    "            \"question\": current_question['prompt'],\n",
    "            \"patient_response\": patient_response,\n",
    "            \"classification\": classification,\n",
    "            \"clarifications_needed\": clarification_count\n",
    "        })\n",
    "        \n",
    "        # Use branching logic to determine next question\n",
    "        branching = current_question.get(\"next\", {})\n",
    "        next_question_id = branching.get(classification, \"END_MODULE\")\n",
    "        \n",
    "        print(f\"Based on '{classification}' response, next: {next_question_id}\")\n",
    "        \n",
    "        if next_question_id == \"END_MODULE\":\n",
    "            interview_state.is_complete = True\n",
    "            print(\"Interview complete based on branching logic.\")\n",
    "        else:\n",
    "            interview_state.current_question_id = next_question_id\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"INTERVIEW COMPLETE\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\nModule: {module_info['name']}\")\n",
    "    print(f\"Total questions asked: {len(interview_state.conversation_log)}\")\n",
    "    \n",
    "    print(\"\\nCONVERSATION SUMMARY:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, entry in enumerate(interview_state.conversation_log, 1):\n",
    "        print(f\"\\n{i}. Question {entry['question_id']}:\")\n",
    "        print(f\"   Clinician: {entry['question']}\")\n",
    "        print(f\"   Patient: {entry['patient_response']}\")\n",
    "        print(f\"   Classification: {entry['classification']}\")\n",
    "        if entry.get('clarifications_needed', 0) > 0:\n",
    "            print(f\"   Clarifications needed: {entry['clarifications_needed']}\")\n",
    "    \n",
    "    interview_state.is_diagnosis = determine_diagnosis(interview_state.conversation_log)\n",
    "\n",
    "    diagnosis_text = \"Positive\" if interview_state.is_diagnosis else \"Negative\"\n",
    "    print(f\"Diagnosis result for Agoraphobia module: {diagnosis_text}\")\n",
    "    \n",
    "    # Export results of the interview to CSV\n",
    "    export_results_to_csv()\n",
    "    \n",
    "    return interview_state.conversation_log\n",
    "\n",
    "# Demo function for testing LLM analysis\n",
    "def run_llm_analysis_demo():\n",
    "    \"\"\"Demonstrate the LLM-powered analysis capabilities.\"\"\"\n",
    "    print(\"=== LLM Analysis Tool Demonstration ===\")\n",
    "    \n",
    "    test_cases = [\n",
    "        (\"yes definitely\", \"Do you feel anxious in crowded places?\"),\n",
    "        (\"not really, maybe sometimes\", \"Do you avoid certain situations?\"),\n",
    "        (\"I get nervous but I still go\", \"Do these situations cause you distress?\"),\n",
    "        (\"absolutely not\", \"Have you experienced panic attacks?\"),\n",
    "        (\"well, it depends on the day\", \"Do you feel this way consistently?\")\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTesting LLM-powered response analysis:\")\n",
    "    for response, question in test_cases:\n",
    "        try:\n",
    "            classification = analyze_response(response, question)\n",
    "            print(f\"'{response}' -> {classification}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing '{response}': {e}\")\n",
    "    \n",
    "    print(\"\\nLLM analysis tool working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Demo Run with Agent Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MINI Module E: Agoraphobia\n",
      "Using AI Agent for intelligent response analysis and clarification\n",
      "======================================================================\n",
      "\n",
      "[Question E1]\n",
      "Clinician: Do you feel anxious or uneasy in places or situations where help might not be available or escape difficult if you had a panic-like or embarrassing symptom, such as being in a crowd or queue, in an open space or crossing a bridge, in an enclosed space, when alone away from home, when alone at home, or traveling in a bus, train, car, or using public transportation?\n",
      "Patient answered: theres a cat climbing up the tree\n",
      "LLM Analysis: unclear\n",
      "\n",
      "[Clarification 1/2]\n",
      "Clinician: \"I appreciate you sharing that with me; it sounds like you’re noticing something interesting. Just to make sure I understand your feelings better, can you tell me if you ever feel anxious or uneasy in situations where you might not have help available, like being in a crowd or traveling alone? A simple 'yes' or 'no' would really help me understand your experience.\"\n"
     ]
    }
   ],
   "source": [
    "# Execute the interview (using the agent-based approach)\n",
    "results = run_interview_with_agent()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
